
# Moderation

::: callout-tip 

## At the end of this chapter, you will be able to:
- Describe moderation
- Check the assumptions of moderation
- Interpret the results of moderation analysis
- Mean centre data for moderation analysis
- Bootstrap moderation analysis

:::

<iframe src="https://teesside.cloud.panopto.eu/Panopto/Pages/Embed.aspx?id=4b8a51de-4fba-4e8c-8c1b-b24a00e2401e&autoplay=false&offerviewer=true&showtitle=true&showbrand=true&captions=false&interactivity=all" height="338" width="600" style="border: 1px solid #464646;" allowfullscreen allow="autoplay" aria-label="Panopto Embedded Video Player" aria-description="Moderation Analysis" ></iframe>

## What is moderation?

Theoretically, we can think of moderation as a relationship between a predictor (X) and an outcome (Y) that is affected by a third variable (M). This means that the relationship between X and Y exists, but the strength of this relationship is affected by the level of M. We could also phrase this as the relationship between X and Y being different, depending on the level of M.

A moderated relationship can be visualised as follows:


![A moderated relationship](images/moderation_model1.png)

```{r  out.height = "75%", echo=F, warning=F, message=F, eval=F}
library(DiagrammeR)
edf <-
  create_edge_df(
    from = c(1,2),
    to = c(4,3),
    color="black",
    # label = c(" ","-","+"),
    fontsize=16)

ndf <- create_node_df(
  n=4,
  label = c("Time in \n counselling", "Rapport with \n counsellor", "", "General Wellbeing"),
  shape = c("rectangle","rectangle","point","rectangle" ), 
  fillcolor = "white", 
  width = c(1.5,1.5,0,1.5), 
  height = c(1,1,0,1),
  x=c(1,3,3,5), 
  y=c(1,2,1,1),
  fontsize=12,
  color="black",
  fontcolor="black")

mod_graph <-
  create_graph(nodes_df = ndf, edges_df = edf)


mod_graph %>% render_graph()

```

In the above model, we theorise that `Time in counselling` predicts `General Wellbeing` but the strength of the relationship is affected by the `level of Rapport` with psychologist. As with all of our hypotheses, the moderated relationship is theorised based on previous research evidence and/or strong theoretical reasoning.

## What packages do we need?

We can do a lot of the moderation analysis with just the `lm()` function in R. However, there are some packages that can make the process easier and help us understand the moderation better. These include:

- **gvlma** (for checking assumptions)
- **interactions** (for generating interaction plot)
- **Rockchalk** (for testing simple slopes)
- **car** (includes a **Boot()** function to bootstrap regression models )


## Moderation as an interaction

When we say that a variable moderates the relationship between two other variables, we are saying that the relationship between the two variables is not the same at different levels of the moderator. This is similar to an interaction in standard regression analysis. In fact, we can tell if there is a moderation effect by looking at the interaction term in a regression model.

`lm(Y ~ X + M + X*M)`

In the above formula, the interaction term is `X*M`. This term is the product of the two variables (X and M). If the interaction term is significant, this suggests that there is a moderation effect.

![A moderated relationship](images/moderation_model1.png)

    
   
    
If the interaction term is significant, this suggests that there is a moderation effect.

However, a moderator can effect the direction and/or strength of a relationship between X and Y. The interaction effect might only be significant when the moderator is at a certain level. The below plot shows a moderated relationship:

```{r echo=F, eval=FALSE}
mod_graph %>% render_graph(title = " ")
```



```{r echo = F, out.width = "60%"}
#setwd("location") #Working directory
set.seed(123)#Standardizes the numbers generated by rnorm; see Chapter 5
N  <- 100 #Number of participants; graduate students
timeInCounselling  <- abs(rnorm(N, 6, 4)) #IV; 
X1 <- abs(rnorm(N, 60, 30)) #Adding some systematic variance for our DV
rapportLevel  <- rnorm(N, 4, 8) #Moderator; years in education
generalWellbeing  <- abs((0.8*-timeInCounselling) * (.1*rapportLevel) + -0.8*timeInCounselling + -0.4*X1 + 10 + rnorm(N, 0, 3)) #DV; 
Moddata <- data.frame(timeInCounselling, rapportLevel, generalWellbeing)


#Moderation "By Hand" with centred data
library(gvlma)
fitMod <- lm(generalWellbeing ~ timeInCounselling *rapportLevel , data = Moddata) #Model interacts IV & moderator

library(interactions)
 ip <- interact_plot(fitMod, pred = timeInCounselling, modx = rapportLevel)
 ip
```


In the plot above:

- The blue line is the "standard" regression line
- The black line is when the moderator is "low" (-1sd)
- The dotted line is when the moderator is "high" (+1sd)


To understand the moderation effect fully, we need some additional analysis.


## Moderation: step-by-step

### Run your model

As with our previous models, we start by running a regression model. In this case, we are interested in the interaction between our predictor and moderator. The model is named `fitMod` and is run using the `lm()` function. The name is not important, but it is good practice to name your models in a way that makes sense to you.

```{r}

fitMod <- lm(generalWellbeing ~ timeInCounselling *rapportLevel , data = Moddata) #Model interacts IV & moderator


```




::: callout-tip
## Grand Mean Centering

In many moderation models, people use grand mean centering. This is a way to make the results of the model easier to interpret. Especially if you have a continuous moderator, it can be helpful to center the data around the grand mean. This means that the mean of the data is subtracted from each value. This makes the mean of the data 0.

This is becuase regression coefficients (b values) are based on predicting Y when X = 0, but not all measures actually have a zero value. To make results easier to interpret, we can centre our data around the grand mean of the data (making the mean 0). The mean of the full sample is subtracted from the value. This is similar to z-score (i.e. a standardised score)

To do this in R, we can use the **scale()** function:

```{r eval=F}
    timeInCounselling_centred    <- scale(timeInCounselling, center=TRUE, scale=FALSE) #Centering X; 
    rapportLevel_centred    <- scale(rapportLevel,  center=TRUE, scale=FALSE) #Centering M;
```

We then use the centred data in our analysis.

We can see that the difference between the original data is the mean of the data.

```{r echo=T}
  timeInCounselling_centred    <- scale(timeInCounselling, center=TRUE, scale=FALSE) #Centering X; 
  
  timeInCounselling
 
  head(timeInCounselling_centred)
  
   mean(timeInCounselling)
  timeInCounselling[1]-timeInCounselling_centred[1]
  

```

```{r}
#Centering Data
Moddata$timeInCounselling_centred    <- c(scale(timeInCounselling, center=TRUE, scale=FALSE)) 

#Centering IV; 
Moddata$rapportLevel_centred    <- c(scale(rapportLevel,  center=TRUE, scale=FALSE)) #Centering moderator; 

#Moderation "By Hand" with centred data
library(gvlma)
fitMod <- lm(generalWellbeing ~ timeInCounselling_centred *rapportLevel_centred  , data = Moddata) #Model interacts IV & moderator

library(interactions)
 ip <- interact_plot(fitMod, pred = timeInCounselling_centred, modx = rapportLevel_centred)
 ip
```

#### Do I need to mean centre my data?

It's really about ease of interpretation. It is worth noting:

- It does not change the results of your interaction (coefficient, standard error or significance tests).
- It will change the results of the direct effects (the individual predictors in your model).
- It is a step that tries to ensure that the coefficients of the predictor and moderator are meaningful to interpret, in relation to each other.
- In some cases, it might not be necessary to mean centre at all. However, there is no harm in doing so, and it could potentially be helpful.

Hayes (2013) discusses mean centering, pp. 282-290. 

:::



### Step 2: Check assumptions


We can use the `gvlma` function to check regression assumptions for moderation analysis. 
```{r}

library(gvlma)
gvlma(fitMod)
```

The "global stat" is an attempt to check multiple assumptions of linear model: Pena, E. A., & Slate, E. H. (2006). Global validation of linear model assumptions. Journal of the American Statistical Association, 101(473), 341-354.

Since one of the underlying assumptions is violated, the overall stat is also not acceptable.

The data looks skewed, we should transform it or perhaps use bootstrapping (we will do this later).

### Multicollinearity?

For more information on multicollinearity in moderation, see Clelland, G. H., Irwin, J. R., Disatnik, D., & Sivan, L. (2017). Multicollinearity is a red herring in the search for moderator variables: A guide to interpreting moderated multiple regression models and a critique of Iacobucci, Schneider, Popovich, and Bakamitsos (2016). Behavior research methods, 49(1), 394-402.


### Step 3: Moderation Analysis

Now that we have run our model and checked the assumptions, we can interpret the results. So we run the `summary()` function on our model.

```{r}

fitMod <- lm(generalWellbeing ~ timeInCounselling_centred *rapportLevel_centred  , data = Moddata) #Model interacts IV & moderator
 #Model interacts IV & moderator
summary(fitMod)
```

The results above show that there is a moderated effect (the interaction term is significant). When the interaction term is significant, this suggests that there is a moderation effect (i.e. the relationship between the predictor and outcome is different at different levels of the moderator). So we do not need to interpret the main effects (timeInCounselling and rapportLevel).

#### Visualising the moderation effect


We use an approach called **simple slopes** to visualise the moderation effect. This is a way to see how the relationship between the predictor and outcome changes at different levels of the moderator. 


`interact_plot(fitMod, pred = timeInCounselling_centred, modx = rapportLevel_centred)`
    
```{r echo=F}
ip
 
```


In the case of the above plot, we can see that the relationship between `timeInCounselling` and `generalWellbeing` is stronger when `rapportLevel` is high (+1sd) compared to when it is low (-1sd). 

The **rockchalk** package includes useful functions for visualising simple slopes

```{r}
library(rockchalk)

fitMod <- lm(generalWellbeing ~ timeInCounselling *rapportLevel  , data = Moddata)
summary(fitMod)


slopes <- plotSlopes(fitMod, modx = "rapportLevel", plotx = "timeInCounselling") #<1>
testSlopes <- testSlopes(slopes) #<2>
plot(testSlopes) #<3>

```

1. The `plotSlopes()` function creates a plot of the simple slopes. We save it as an object so we can use it later.
2. The `testSlopes()` function tests the simple slopes. This is to see if the slopes are significant.
3. The `plot()` function is used to plot the results of the simple slopes test. This tells us at which level of the moderator the slopes are significant.

In the example above, we can see that the slope of the relationship between `timeInCounselling` and `generalWellbeing` is significant when the moderator is between -11.58 and 3.63. We can look at the simple slopes plot to see how the relationship changes at these levels. We can also check whether -11.58 and 3.63 are within the range of the moderator variable (`rapportLevel`) - if this is not the case, we only consider the values that are within the possible range of the moderator variable.

### Step 4: Bootstrapping

We saw in the regression diagnostics that the data was skewed. We can use bootstrapping to get a more accurate estimate of the confidence intervals. The **car** package includes a function to bootstrap any regression

```{r}
library(car)

bootstrapModel <- Boot(fitMod, R=999) #<1>

confint(fitMod) #<2>
confint(bootstrapModel) #<3>
summary(bootstrapModel) #<4>
hist(bootstrapModel) #<5>
```

1. The `Boot()` function is used to bootstrap the model. We save the results as an object called `bootstrapModel`.
2. We can use the `confint()` function to get the confidence intervals of the original model.
3. We can use the `confint()` function to get the confidence intervals of the bootstrapped model.
4. We can use the `summary()` function to get a summary of the bootstrapped model.
5. We can use the `hist()` function to plot a histogram of the bootstrapped model.

Comparing the confidence intervals of the original model and the bootstrapped model can give us an idea of how accurate our original model is. If the confidence intervals are very different, this suggests that the original model is not very accurate. In this case, we might want to use the bootstrapped model instead. 

The bootBias and bootSE columns in the summary of the bootstrapped model can also give us an idea of how much the bootstrapped model differs from the original model. If the bootBias is very different from 0, this suggests that the original model is biased. If the bootSE is very different from the original SE, this suggests that the original model is not very accurate.

In the data above, we can see that the bootBias and bootSE are very close to 0 and the original SE, respectively. This suggests that the deviation from normality is not a big problem in this case.


 
